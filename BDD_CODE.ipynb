{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDD_CODE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxg2M7SpBQToNJudkwx6dg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bahulkark/Building-your-Deep-Neural-Network-Step-by-Step/blob/master/BDD_CODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLyVLw12clcI",
        "outputId": "b254c70e-219c-4239-839f-62c6f170a8fa"
      },
      "source": [
        "## now we install TOG \n",
        "## to generate patched images.\n",
        "\n",
        "!git clone https://github.com/git-disl/TOG\n",
        "%cd ./TOG\n",
        "# !pip install -r requirements.txt\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TOG'...\n",
            "remote: Enumerating objects: 348, done.\u001b[K\n",
            "remote: Counting objects: 100% (348/348), done.\u001b[K\n",
            "remote: Compressing objects: 100% (297/297), done.\u001b[K\n",
            "remote: Total 348 (delta 65), reused 290 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (348/348), 42.76 MiB | 26.28 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "/content/TOG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0eK93NToKT0"
      },
      "source": [
        "%cd ./TOG/\n",
        "# %tensorflow_version 1.x\n",
        "from attack_utils.patch_utils import extract_roi, extract_roi_multi, evaluate_vanishing_patch\n",
        "from dataset_utils.preprocessing import letterbox_image_padded\n",
        "from models.yolov3 import YOLOv3_Darknet53\n",
        "from misc_utils.visualization import visualize_detections\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "from tog.attacks import *\n",
        "\n",
        "K.clear_session() \n",
        "\n",
        "weights = '/content/TOG/yolo_bdd.h5'  # TODO: Change this path to the victim model's weights\n",
        "detector = YOLOv3_Darknet53(weights=weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdC-_CLAnubU"
      },
      "source": [
        "## rm rf ?? \n",
        "# !rm -rf /content/TOG/assets\n",
        "# !rm -rf /content/TOG/frcnn_utils\n",
        "# !rm -rf /content/TOG/ssd_utils\n",
        "# !rm ./*.ipynb"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHPQ7veTn3my"
      },
      "source": [
        "## edit/future edit ??\n",
        "\n",
        "# 1. edit patch_utils. for extract_roi asap \n",
        "# (DONE)2. edit visuallizations for new_vis = save function \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh06J5tHNZIx"
      },
      "source": [
        "## download scripts \n",
        "\n",
        "\n",
        "## kitti\n",
        "# ## dld model \n",
        "# #https://drive.google.com/file/d/1--bzF2qygux4XVar4FWr4Aux9aIUt5Z-/view?usp=sharing\n",
        "# wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1--bzF2qygux4XVar4FWr4Aux9aIUt5Z-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1--bzF2qygux4XVar4FWr4Aux9aIUt5Z-\" -O kitti_full.zip && rm -rf /tmp/cookies.txt\n",
        "# #wget https://pjreddie.com/media/files/yolov3.weights\n",
        "# unzip kitti_full.zip\n",
        "\n",
        "# ## bdd\n",
        "# ## dld model \n",
        "# #https://drive.google.com/file/d/1y8M7mEomuehHQBplDeMIe1pBZIxF59-w/view?usp=sharing\n",
        "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1y8M7mEomuehHQBplDeMIe1pBZIxF59-w' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1y8M7mEomuehHQBplDeMIe1pBZIxF59-w\" -O yolo_bdd.h5 && rm -rf /tmp/cookies.txt\n",
        "\n",
        "# ## dld model weights\n",
        "\n",
        "\n",
        "# ## dld datasets. \n",
        "# #https://drive.google.com/file/d/1OOL4vcQNV34gQ_ZFt5oOM6KWij-AXRiq/view?usp=sharing\n",
        "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1OOL4vcQNV34gQ_ZFt5oOM6KWij-AXRiq' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1OOL4vcQNV34gQ_ZFt5oOM6KWij-AXRiq\" -O bdd_processed.zip && rm -rf /tmp/cookies.txt\n",
        "\n",
        "\n",
        "!unzip bdd_processed.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTfvO8dpSOK4"
      },
      "source": [
        "!git clone https://github.com/AlexeyAB/darknet\n",
        "%cd ./darknet\n",
        "#Edit the makefile to enable gpu and opencv\n",
        "!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
        "#Make darknet\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JXmfGEuPyUN"
      },
      "source": [
        "## fix this to exclude colab drives. \n",
        "!mkdir -p ./labels/val\n",
        "!mkdir -p ./labels/train\n",
        "\n",
        "import os \n",
        "import shutil\n",
        "lst = os.listdir(\"/content/TOG/images/val\")\n",
        "for file in lst:\n",
        "  if file[-3:] == \"txt\":\n",
        "    shutil.copyfile(\"/content/TOG/images/val/\"+file, \"/content/TOG/darknet/labels/val/\"+file)\n",
        "    \n",
        "import os \n",
        "import shutil\n",
        "lst = os.listdir(\"/content/TOG/images/train\")\n",
        "for file in lst:\n",
        "  if file[-3:] == \"txt\":\n",
        "    shutil.copyfile(\"/content/TOG/images/train/\"+file, \"/content/TOG/darknet/labels/train/\"+file)\n",
        "\n",
        "%cd /content/TOG/images/train\n",
        "!find . -name \"*.txt\" -type f -delete\n",
        "\n",
        "%cd /content/TOG/images/val\n",
        "!find . -name \"*.txt\" -type f -delete\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IomZVTm2L3wy"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqsfi76HPZNX"
      },
      "source": [
        "## do that thing. \n",
        "\n",
        "ROOT_TRAIN = '/content/TOG/images/train'\n",
        "ROOT_TEST = '/content/TOG/images/test'\n",
        "ROOT_OUTPUT = '/content/drive/MyDrive/bdd_colab/pro_bdd_patchs/'\n",
        "NUM_EPOCHS = 100\n",
        "LR_INIT = 0.1\n",
        "LR_MULTIPLIER = 0.1\n",
        "BATCH_SIZE = 16\n",
        "TOLERANCE_MAX = 5\n",
        "TOLERANCE_DELTA = 0.01\n",
        "SOURCE_CLASS = 'car'\n",
        "\n",
        "\n",
        "## in decreasing order\n",
        "PATCH_SIZES = [(64,64), (32,32), (14,14), (10,10), (6,6)]\n",
        "patches = [np.full(shape=(1, *PATCH_SIZE, 3), fill_value=0.50) for _ in range(len(PATCH_SIZES))]\n",
        "lr = [LR_INIT for _ in range(len(PATCH_SIZES))]\n",
        "\n",
        "\n",
        "fpaths_train = [os.path.join(ROOT_TRAIN, fname) for fname in os.listdir(ROOT_TRAIN)\n",
        "fpaths_test = [os.path.join(ROOT_TEST, fname) for fname in os.listdir(ROOT_TEST)]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "UL112HYAfCI_",
        "outputId": "fb4ba42c-91f2-482a-976e-83a9b131743c"
      },
      "source": [
        "print(\"training patchs: \", PATCH_SIZES)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3022d7a6404e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training patchS: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATCH_SIZES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'PATCH_SIZES' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7sNxmdSDeTb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpL8WhjjPZDw"
      },
      "source": [
        "## Notice which rois to consider... \n",
        "## *** Current training: exclusive patch of size 6x6. \n",
        "\n",
        "\n",
        "\n",
        "for ip, patch in patches:\n",
        "    print(\"training patch: \", PATCH_SIZES[ip])\n",
        "    min_loss = np.float('inf')\n",
        "    tolerance = 0\n",
        "\n",
        "    output_folder = os.path.join(ROOT_OUTPUT, 'pro_vanishing_multi_{}'.format(PATCH_SIZES[ip]),\n",
        "                                '%s_%s' % (datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\"), SOURCE_CLASS))\n",
        "    os.makedirs(output_folder)\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        ####################################################################################################################\n",
        "        # Training\n",
        "        ####################################################################################################################\n",
        "        epoch_loss = []\n",
        "        batch_grad, batch_loss = [], []\n",
        "        np.random.shuffle(fpaths_train)\n",
        "        for fpath in tqdm(fpaths_train):\n",
        "            # Preprocess input images\n",
        "            input_img = Image.open(fpath)\n",
        "            x_nat, x_bbox = letterbox_image_padded(input_img, size=detector.model_img_size)\n",
        "\n",
        "            # Get roi candidates with an area higher than a predefined threshold to avoid trivial attacks\n",
        "            detections_nat = detector.detect(x_nat, iou_threshold=.5, conf_threshold=.7)\n",
        "            rois = extract_roi2(detections_nat, detector.classes.index(SOURCE_CLASS), (0, 0, 256, 416), min_size=MIN_ROI_SIZE, patch_size=PATCH_SIZE, input_img=x_nat[0, :, :, :], model_img_size=detector.model_img_size)\n",
        "            if len(rois) == 0:\n",
        "                continue\n",
        "\n",
        "            # Apply adversarial patch to each of the rois\n",
        "            x_adv = x_nat.copy()\n",
        "            detections_target = detections_nat.copy()\n",
        "            try:\n",
        "                for _, _, (xmin, ymin, xmax, ymax), did in rois:\n",
        "                    x_adv[:, ymin:ymax, xmin:xmax, :] = patch\n",
        "            except Exception:\n",
        "                pass\n",
        "            # visualize_detections_basic2(\"./debug_out/\"+str(ix), {'Original Image': (x_adv, detections_target, detector.model_img_size, detector.classes),\n",
        "            #                     'patched_image': (x_adv, detections_target, detector.model_img_size, detector.classes)})\n",
        "\n",
        "\n",
        "            # Compute gradients\n",
        "            grad, loss = detector.compute_object_vanishing_gradient_and_loss(x_adv, detections=detections_target)\n",
        "\n",
        "            # Clip gradients to the area where the adversarial patch is located\n",
        "            grad = np.mean([grad[:, ymin:ymax, xmin:xmax, :] for _, _, (xmin, ymin, xmax, ymax), _ in rois], axis=0)\n",
        "            batch_grad.append(grad)\n",
        "            batch_loss.append(loss)\n",
        "\n",
        "            if len(batch_loss) == BATCH_SIZE:  # Update the adversarial patch and log the loss over the mini-batch\n",
        "                # print(patch.shape)\n",
        "                # print(batch_grad[0].shape)\n",
        "                patch = np.clip(patch - lr * np.mean(batch_grad, axis=0), 0.0, 1.0)\n",
        "                epoch_loss.append(np.mean(batch_loss))\n",
        "                batch_grad, batch_loss = [], []\n",
        "\n",
        "        ####################################################################################################################\n",
        "        # Testing\n",
        "        ####################################################################################################################\n",
        "        # Baseline = Random permutation of the adversarial patch (i.e., decorrelating pixels)\n",
        "        patch_rand = np.reshape(patch.copy(), newshape=(patch.shape[0]*patch.shape[1]*patch.shape[2], patch.shape[3]))\n",
        "        np.random.shuffle(patch_rand)\n",
        "        patch_rand = np.reshape(patch_rand, newshape=patch.shape)\n",
        "        num_rois, score_adv, score_rand = 0, 0, 0\n",
        "        for fpath in fpaths_test:\n",
        "            input_img = Image.open(fpath)\n",
        "            x_nat, x_bbox = letterbox_image_padded(input_img, size=detector.model_img_size)\n",
        "\n",
        "            # Get roi candidates with an area higher than a predefined threshold to avoid trivial attacks\n",
        "            detections_nat = detector.detect(x_nat, iou_threshold=.5, conf_threshold=.7)\n",
        "            rois = extract_roi2(detections_nat, detector.classes.index(SOURCE_CLASS), (0, 0, 256, 416), min_size=MIN_ROI_SIZE, patch_size=PATCH_SIZE, input_img=x_nat[0, :, :, :], model_img_size=detector.model_img_size)\n",
        "            num_rois_x = len(rois)\n",
        "            if num_rois_x == 0:\n",
        "                continue\n",
        "\n",
        "            x_adv, x_rand = x_nat.copy(), x_nat.copy()\n",
        "            try: \n",
        "                for _, _, (xmin, ymin, xmax, ymax), _ in rois:\n",
        "                    x_adv[:, ymin:ymax, xmin:xmax, :] = patch\n",
        "                    x_rand[:, ymin:ymax, xmin:xmax, :] = patch_rand\n",
        "            except Exception:\n",
        "                pass\n",
        "            detections_adv = detector.detect(x_adv, iou_threshold=.5, conf_threshold=.7)\n",
        "            detections_rand = detector.detect(x_rand, iou_threshold=.5, conf_threshold=.7)\n",
        "            # visualize_detections_basic2(\"./debug_out/test_\"+str(ix), {'Original Image': (x_adv, detections_target, detector.model_img_size, detector.classes),\n",
        "            #                     'patched_image': (x_adv, detections_target, detector.model_img_size, detector.classes)})\n",
        "\n",
        "\n",
        "            score_adv_x, score_rand_x = evaluate_vanishing_patch(detector.classes.index(SOURCE_CLASS), rois, detections_adv, detections_rand)\n",
        "            score_adv += score_adv_x\n",
        "            score_rand += score_rand_x\n",
        "            num_rois += num_rois_x\n",
        "\n",
        "        # Compute training statistics\n",
        "        epoch_loss = float(np.mean(epoch_loss))\n",
        "        ASR_TOG = score_adv / num_rois\n",
        "        ASR_Rand = score_rand / num_rois\n",
        "\n",
        "        # Save the adversarial patch\n",
        "        np.save(os.path.join(output_folder, 'exclusive_Epoch-%d_Loss-%.2f_ASR-%.2f.npy' % (epoch, epoch_loss, ASR_TOG)), patch)\n",
        "\n",
        "        # Monitor training loss for learning rate scheduling\n",
        "        if epoch_loss > min_loss - TOLERANCE_DELTA:\n",
        "            tolerance += 1\n",
        "            if tolerance >= TOLERANCE_MAX:\n",
        "                lr[ip] *= LR_MULTIPLIER\n",
        "                tolerance = 0\n",
        "        else:\n",
        "            tolerance = 0\n",
        "        min_loss = min(min_loss, epoch_loss)\n",
        "\n",
        "        # Print training progress\n",
        "        print('[Epoch %d] LR: %f | Tol: %d/%d | Min. Loss: %.4f' % (epoch, lr, tolerance + 1, TOLERANCE_MAX, min_loss))\n",
        "        print('  > Loss      : %.4f' % epoch_loss)\n",
        "        print('  > ASR (TOG) : %d/%d = %.2f' % (score_adv, num_rois, ASR_TOG))\n",
        "        print('  > ASR (Rand): %d/%d = %.2f' % (score_rand, num_rois, ASR_Rand))\n",
        "        if (lr[ip] == 0.0):\n",
        "            print(\"LR converged to 0.0. Stopping Training for patch {}\".format(patches[ip]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpQMpj__Lku5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLUJTdkgLkqQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2IdHIR0Lkl8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIC9QaxZbm50"
      },
      "source": [
        "!rm -rf /content/TOG/json"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JmnRHOkBbqid",
        "outputId": "fadc0b52-be4b-471d-916e-38556b962f46"
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive(\"/content/multipatchreal\", \"zip\", \"/content/TOG\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/multipatchreal.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZs230cVb3p0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}